import { generateText } from "../../model-function/generate-text/generateText.js";
import { splitAtToken } from "../../text-chunk/split/splitRecursively.js";
import { summarizeRecursively } from "./summarizeRecursively.js";
/**
 * Recursively summarizes a text using a text generation model, e.g. for summarization or text extraction.
 * It automatically splits the text into optimal chunks that are small enough to be processed by the model,
 * while leaving enough space for the model to generate text.
 */
export async function summarizeRecursivelyWithTextGenerationAndTokenSplitting({ text, model, prompt, tokenLimit = model.contextWindowSize -
    (model.settings.maxCompletionTokens ?? model.contextWindowSize / 4), join, }, options) {
    const emptyPromptTokens = await model.countPromptTokens(await prompt({ text: "" }));
    return summarizeRecursively({
        split: splitAtToken({
            tokenizer: model.tokenizer,
            maxTokensPerChunk: tokenLimit - emptyPromptTokens,
        }),
        summarize: async (input) => generateText(model, await prompt(input), options),
        join,
        text,
    }, options);
}
