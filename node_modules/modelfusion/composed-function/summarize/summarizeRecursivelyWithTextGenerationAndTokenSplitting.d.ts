import { Run } from "../../core/Run.js";
import { TextGenerationModel } from "../../model-function/generate-text/TextGenerationModel.js";
import { FullTokenizer } from "../../model-function/tokenize-text/Tokenizer.js";
/**
 * Recursively summarizes a text using a text generation model, e.g. for summarization or text extraction.
 * It automatically splits the text into optimal chunks that are small enough to be processed by the model,
 * while leaving enough space for the model to generate text.
 */
export declare function summarizeRecursivelyWithTextGenerationAndTokenSplitting<PROMPT>({ text, model, prompt, tokenLimit, join, }: {
    text: string;
    model: TextGenerationModel<PROMPT> & {
        contextWindowSize: number;
        tokenizer: FullTokenizer;
        countPromptTokens: (prompt: PROMPT) => PromiseLike<number>;
    };
    prompt: (input: {
        text: string;
    }) => Promise<PROMPT>;
    tokenLimit?: number;
    join?: (texts: Array<string>) => string;
}, options?: {
    functionId?: string;
    run?: Run;
}): Promise<string>;
