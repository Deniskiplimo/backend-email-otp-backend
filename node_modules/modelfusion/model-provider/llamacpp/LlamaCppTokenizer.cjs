"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.LlamaCppTokenizer = void 0;
const zod_1 = require("zod");
const callWithRetryAndThrottle_js_1 = require("../../core/api/callWithRetryAndThrottle.cjs");
const postToApi_js_1 = require("../../core/api/postToApi.cjs");
const LlamaCppApiConfiguration_js_1 = require("./LlamaCppApiConfiguration.cjs");
const LlamaCppError_js_1 = require("./LlamaCppError.cjs");
/**
 * Tokenizer for LlamaCpp.

 * @example
 * const tokenizer = new LlamaCppTokenizer();
 *
 * const text = "At first, Nox didn't know what to do with the pup.";
 *
 * const tokenCount = await countTokens(tokenizer, text);
 * const tokens = await tokenizer.tokenize(text);
 * const tokensAndTokenTexts = await tokenizer.tokenizeWithTexts(text);
 * const reconstructedText = await tokenizer.detokenize(tokens);
 */
class LlamaCppTokenizer {
    constructor(api = new LlamaCppApiConfiguration_js_1.LlamaCppApiConfiguration()) {
        Object.defineProperty(this, "api", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.api = api;
    }
    async callTokenizeAPI(text, context) {
        return (0, callWithRetryAndThrottle_js_1.callWithRetryAndThrottle)({
            retry: this.api.retry,
            throttle: this.api.throttle,
            call: async () => callLlamaCppTokenizeAPI({
                api: this.api,
                abortSignal: context?.abortSignal,
                text,
            }),
        });
    }
    async tokenize(text) {
        const response = await this.callTokenizeAPI(text);
        return response.tokens;
    }
}
exports.LlamaCppTokenizer = LlamaCppTokenizer;
const llamaCppTokenizationResponseSchema = zod_1.z.object({
    tokens: zod_1.z.array(zod_1.z.number()),
});
async function callLlamaCppTokenizeAPI({ api, abortSignal, text, }) {
    return (0, postToApi_js_1.postJsonToApi)({
        url: api.assembleUrl(`/tokenize`),
        headers: api.headers,
        body: {
            content: text,
        },
        failedResponseHandler: LlamaCppError_js_1.failedLlamaCppCallResponseHandler,
        successfulResponseHandler: (0, postToApi_js_1.createJsonResponseHandler)(llamaCppTokenizationResponseSchema),
        abortSignal,
    });
}
