"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.OpenAITranscriptionResponseFormat = exports.OpenAITranscriptionModel = exports.calculateOpenAITranscriptionCostInMillicents = exports.OPENAI_TRANSCRIPTION_MODELS = void 0;
const zod_1 = require("zod");
const callWithRetryAndThrottle_js_1 = require("../../core/api/callWithRetryAndThrottle.cjs");
const postToApi_js_1 = require("../../core/api/postToApi.cjs");
const AbstractModel_js_1 = require("../../model-function/AbstractModel.cjs");
const OpenAIApiConfiguration_js_1 = require("./OpenAIApiConfiguration.cjs");
const OpenAIError_js_1 = require("./OpenAIError.cjs");
/**
 * @see https://openai.com/pricing
 */
exports.OPENAI_TRANSCRIPTION_MODELS = {
    "whisper-1": {
        costInMillicentsPerSecond: 10, // = 600 / 60,
    },
};
const calculateOpenAITranscriptionCostInMillicents = ({ model, response, }) => {
    if (model !== "whisper-1") {
        return null;
    }
    const durationInSeconds = response.duration;
    return (Math.ceil(durationInSeconds) *
        exports.OPENAI_TRANSCRIPTION_MODELS[model].costInMillicentsPerSecond);
};
exports.calculateOpenAITranscriptionCostInMillicents = calculateOpenAITranscriptionCostInMillicents;
/**
 * Create a transcription model that calls the OpenAI transcription API.
 *
 * @see https://platform.openai.com/docs/api-reference/audio/create
 *
 * @example
 * const data = await fs.promises.readFile("data/test.mp3");
 *
 * const transcription = await transcribe(
 *   new OpenAITranscriptionModel({ model: "whisper-1" }),
 *   {
 *     type: "mp3",
 *     data,
 *   }
 * );
 */
class OpenAITranscriptionModel extends AbstractModel_js_1.AbstractModel {
    constructor(settings) {
        super({ settings });
        Object.defineProperty(this, "provider", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "openai"
        });
    }
    get modelName() {
        return this.settings.model;
    }
    async doTranscribe(data, options) {
        const response = await this.callAPI(data, {
            responseFormat: exports.OpenAITranscriptionResponseFormat.verboseJson,
            functionId: options?.functionId,
            run: options?.run,
        });
        return {
            response,
            transcription: response.text,
        };
    }
    async callAPI(data, options) {
        return (0, callWithRetryAndThrottle_js_1.callWithRetryAndThrottle)({
            retry: this.settings.api?.retry,
            throttle: this.settings.api?.throttle,
            call: async () => callOpenAITranscriptionAPI({
                ...this.settings,
                // other settings:
                abortSignal: options?.run?.abortSignal,
                file: {
                    name: `audio.${data.type}`,
                    data: data.data,
                },
                responseFormat: options?.responseFormat,
            }),
        });
    }
    get settingsForEvent() {
        return {};
    }
    withSettings(additionalSettings) {
        return new OpenAITranscriptionModel(Object.assign({}, this.settings, additionalSettings));
    }
}
exports.OpenAITranscriptionModel = OpenAITranscriptionModel;
async function callOpenAITranscriptionAPI({ api = new OpenAIApiConfiguration_js_1.OpenAIApiConfiguration(), abortSignal, model, file, prompt, responseFormat, temperature, language, }) {
    const formData = new FormData();
    formData.append("file", new Blob([file.data]), file.name);
    formData.append("model", model);
    if (prompt) {
        formData.append("prompt", prompt);
    }
    if (responseFormat) {
        formData.append("response_format", responseFormat.type);
    }
    if (temperature) {
        formData.append("temperature", temperature.toString());
    }
    if (language) {
        formData.append("language", language);
    }
    return (0, postToApi_js_1.postToApi)({
        url: api.assembleUrl("/audio/transcriptions"),
        headers: api.headers,
        body: {
            content: formData,
            values: {
                model,
                prompt,
                response_format: responseFormat,
                temperature,
                language,
            },
        },
        failedResponseHandler: OpenAIError_js_1.failedOpenAICallResponseHandler,
        successfulResponseHandler: responseFormat.handler,
        abortSignal,
    });
}
const openAITranscriptionJsonSchema = zod_1.z.object({
    text: zod_1.z.string(),
});
const openAITranscriptionVerboseJsonSchema = zod_1.z.object({
    task: zod_1.z.literal("transcribe"),
    language: zod_1.z.string(),
    duration: zod_1.z.number(),
    segments: zod_1.z.array(zod_1.z.object({
        id: zod_1.z.number(),
        seek: zod_1.z.number(),
        start: zod_1.z.number(),
        end: zod_1.z.number(),
        text: zod_1.z.string(),
        tokens: zod_1.z.array(zod_1.z.number()),
        temperature: zod_1.z.number(),
        avg_logprob: zod_1.z.number(),
        compression_ratio: zod_1.z.number(),
        no_speech_prob: zod_1.z.number(),
        transient: zod_1.z.boolean().optional(),
    })),
    text: zod_1.z.string(),
});
exports.OpenAITranscriptionResponseFormat = {
    json: {
        type: "json",
        handler: (0, postToApi_js_1.createJsonResponseHandler)(openAITranscriptionJsonSchema),
    },
    verboseJson: {
        type: "verbose_json",
        handler: (0, postToApi_js_1.createJsonResponseHandler)(openAITranscriptionVerboseJsonSchema),
    },
    text: {
        type: "text",
        handler: (0, postToApi_js_1.createTextResponseHandler)(),
    },
    srt: {
        type: "srt",
        handler: (0, postToApi_js_1.createTextResponseHandler)(),
    },
    vtt: {
        type: "vtt",
        handler: (0, postToApi_js_1.createTextResponseHandler)(),
    },
};
