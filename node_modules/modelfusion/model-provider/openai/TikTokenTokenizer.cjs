"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.TikTokenTokenizer = void 0;
const lite_1 = require("js-tiktoken/lite");
const cl100k_base_1 = __importDefault(require("js-tiktoken/ranks/cl100k_base"));
const p50k_base_1 = __importDefault(require("js-tiktoken/ranks/p50k_base"));
const r50k_base_1 = __importDefault(require("js-tiktoken/ranks/r50k_base"));
const never_js_1 = require("../../util/never.cjs");
/**
 * TikToken tokenizer for OpenAI language models.
 *
 * @see https://github.com/openai/tiktoken
 *
 * @example
 * const tokenizer = new TikTokenTokenizer({ model: "gpt-4" });
 *
 * const text = "At first, Nox didn't know what to do with the pup.";
 *
 * const tokenCount = await countTokens(tokenizer, text);
 * const tokens = await tokenizer.tokenize(text);
 * const tokensAndTokenTexts = await tokenizer.tokenizeWithTexts(text);
 * const reconstructedText = await tokenizer.detokenize(tokens);
 */
class TikTokenTokenizer {
    /**
     * Get a TikToken tokenizer for a specific model or encoding.
     */
    constructor(options) {
        Object.defineProperty(this, "tiktoken", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.tiktoken = new lite_1.Tiktoken(getTiktokenBPE(options.model));
    }
    async tokenize(text) {
        return this.tiktoken.encode(text);
    }
    async tokenizeWithTexts(text) {
        const tokens = this.tiktoken.encode(text);
        return {
            tokens,
            tokenTexts: tokens.map((token) => this.tiktoken.decode([token])),
        };
    }
    async detokenize(tokens) {
        return this.tiktoken.decode(tokens);
    }
}
exports.TikTokenTokenizer = TikTokenTokenizer;
// implemented here (instead of using js-tiktoken) to be able to quickly updated it
// when new models are released
function getTiktokenBPE(model) {
    switch (model) {
        case "code-davinci-002":
        case "text-davinci-002":
        case "text-davinci-003": {
            return p50k_base_1.default;
        }
        case "ada":
        case "babbage":
        case "curie":
        case "davinci":
        case "text-ada-001":
        case "text-babbage-001":
        case "text-curie-001": {
            return r50k_base_1.default;
        }
        case "babbage-002":
        case "davinci-002":
        case "gpt-3.5-turbo":
        case "gpt-3.5-turbo-0301":
        case "gpt-3.5-turbo-0613":
        case "gpt-3.5-turbo-16k":
        case "gpt-3.5-turbo-16k-0613":
        case "gpt-3.5-turbo-instruct":
        case "gpt-4":
        case "gpt-4-0314":
        case "gpt-4-0613":
        case "gpt-4-32k":
        case "gpt-4-32k-0314":
        case "gpt-4-32k-0613":
        case "text-embedding-ada-002": {
            return cl100k_base_1.default;
        }
        default: {
            (0, never_js_1.never)(model);
            throw new Error(`Unknown model: ${model}`);
        }
    }
}
