"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.OpenAITextEmbeddingModel = exports.calculateOpenAIEmbeddingCostInMillicents = exports.isOpenAIEmbeddingModel = exports.OPENAI_TEXT_EMBEDDING_MODELS = void 0;
const zod_1 = require("zod");
const callWithRetryAndThrottle_js_1 = require("../../core/api/callWithRetryAndThrottle.cjs");
const postToApi_js_1 = require("../../core/api/postToApi.cjs");
const AbstractModel_js_1 = require("../../model-function/AbstractModel.cjs");
const countTokens_js_1 = require("../../model-function/tokenize-text/countTokens.cjs");
const OpenAIApiConfiguration_js_1 = require("./OpenAIApiConfiguration.cjs");
const OpenAIError_js_1 = require("./OpenAIError.cjs");
const TikTokenTokenizer_js_1 = require("./TikTokenTokenizer.cjs");
exports.OPENAI_TEXT_EMBEDDING_MODELS = {
    "text-embedding-ada-002": {
        contextWindowSize: 8192,
        embeddingDimensions: 1536,
        tokenCostInMillicents: 0.01,
    },
};
const isOpenAIEmbeddingModel = (model) => model in exports.OPENAI_TEXT_EMBEDDING_MODELS;
exports.isOpenAIEmbeddingModel = isOpenAIEmbeddingModel;
const calculateOpenAIEmbeddingCostInMillicents = ({ model, responses, }) => {
    let amountInMilliseconds = 0;
    for (const response of responses) {
        amountInMilliseconds +=
            response.usage.total_tokens *
                exports.OPENAI_TEXT_EMBEDDING_MODELS[model].tokenCostInMillicents;
    }
    return amountInMilliseconds;
};
exports.calculateOpenAIEmbeddingCostInMillicents = calculateOpenAIEmbeddingCostInMillicents;
/**
 * Create a text embedding model that calls the OpenAI embedding API.
 *
 * @see https://platform.openai.com/docs/api-reference/embeddings
 *
 * @example
 * const embeddings = await embedMany(
 *   new OpenAITextEmbeddingModel({ model: "text-embedding-ada-002" }),
 *   [
 *     "At first, Nox didn't know what to do with the pup.",
 *     "He keenly observed and absorbed everything around him, from the birds in the sky to the trees in the forest.",
 *   ]
 * );
 */
class OpenAITextEmbeddingModel extends AbstractModel_js_1.AbstractModel {
    constructor(settings) {
        super({ settings });
        Object.defineProperty(this, "provider", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "openai"
        });
        Object.defineProperty(this, "maxValuesPerCall", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: 2048
        });
        Object.defineProperty(this, "embeddingDimensions", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "tokenizer", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "contextWindowSize", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.tokenizer = new TikTokenTokenizer_js_1.TikTokenTokenizer({ model: this.modelName });
        this.contextWindowSize =
            exports.OPENAI_TEXT_EMBEDDING_MODELS[this.modelName].contextWindowSize;
        this.embeddingDimensions =
            exports.OPENAI_TEXT_EMBEDDING_MODELS[this.modelName].embeddingDimensions;
    }
    get modelName() {
        return this.settings.model;
    }
    async countTokens(input) {
        return (0, countTokens_js_1.countTokens)(this.tokenizer, input);
    }
    async callAPI(texts, options) {
        return (0, callWithRetryAndThrottle_js_1.callWithRetryAndThrottle)({
            retry: this.settings.api?.retry,
            throttle: this.settings.api?.throttle,
            call: async () => callOpenAITextEmbeddingAPI({
                ...this.settings,
                user: this.settings.isUserIdForwardingEnabled
                    ? options?.run?.userId
                    : undefined,
                abortSignal: options?.run?.abortSignal,
                input: texts,
            }),
        });
    }
    get settingsForEvent() {
        return {};
    }
    async doEmbedValues(texts, options) {
        if (texts.length > this.maxValuesPerCall) {
            throw new Error(`The OpenAI embedding API only supports ${this.maxValuesPerCall} texts per API call.`);
        }
        const response = await this.callAPI(texts, options);
        return {
            response,
            embeddings: response.data.map((data) => data.embedding),
        };
    }
    withSettings(additionalSettings) {
        return new OpenAITextEmbeddingModel(Object.assign({}, this.settings, additionalSettings));
    }
}
exports.OpenAITextEmbeddingModel = OpenAITextEmbeddingModel;
const openAITextEmbeddingResponseSchema = zod_1.z.object({
    object: zod_1.z.literal("list"),
    data: zod_1.z.array(zod_1.z.object({
        object: zod_1.z.literal("embedding"),
        embedding: zod_1.z.array(zod_1.z.number()),
        index: zod_1.z.number(),
    })),
    model: zod_1.z.string(),
    usage: zod_1.z.object({
        prompt_tokens: zod_1.z.number(),
        total_tokens: zod_1.z.number(),
    }),
});
async function callOpenAITextEmbeddingAPI({ api = new OpenAIApiConfiguration_js_1.OpenAIApiConfiguration(), abortSignal, model, input, user, }) {
    return (0, postToApi_js_1.postJsonToApi)({
        url: api.assembleUrl("/embeddings"),
        headers: api.headers,
        body: {
            model,
            input,
            user,
        },
        failedResponseHandler: OpenAIError_js_1.failedOpenAICallResponseHandler,
        successfulResponseHandler: (0, postToApi_js_1.createJsonResponseHandler)(openAITextEmbeddingResponseSchema),
        abortSignal,
    });
}
