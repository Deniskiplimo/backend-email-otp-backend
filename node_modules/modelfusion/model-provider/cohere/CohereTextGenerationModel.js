import { z } from "zod";
import { callWithRetryAndThrottle } from "../../core/api/callWithRetryAndThrottle.js";
import { createJsonResponseHandler, postJsonToApi, } from "../../core/api/postToApi.js";
import { AsyncQueue } from "../../event-source/AsyncQueue.js";
import { AbstractModel } from "../../model-function/AbstractModel.js";
import { PromptFormatTextStreamingModel } from "../../model-function/generate-text/PromptFormatTextStreamingModel.js";
import { mapChatPromptToTextFormat, mapInstructionPromptToTextFormat, } from "../../model-function/generate-text/TextPromptFormat.js";
import { countTokens } from "../../model-function/tokenize-text/countTokens.js";
import { parseJsonWithZod } from "../../util/parseJSON.js";
import { CohereApiConfiguration } from "./CohereApiConfiguration.js";
import { failedCohereCallResponseHandler } from "./CohereError.js";
import { CohereTokenizer } from "./CohereTokenizer.js";
export const COHERE_TEXT_GENERATION_MODELS = {
    command: {
        contextWindowSize: 2048,
    },
    "command-nightly": {
        contextWindowSize: 2048,
    },
    "command-light": {
        contextWindowSize: 2048,
    },
    "command-light-nightly": {
        contextWindowSize: 2048,
    },
};
/**
 * Create a text generation model that calls the Cohere Co.Generate API.
 *
 * @see https://docs.cohere.com/reference/generate
 *
 * @example
 * const model = new CohereTextGenerationModel({
 *   model: "command-nightly",
 *   temperature: 0.7,
 *   maxCompletionTokens: 500,
 * });
 *
 * const text = await generateText(
 *    model,
 *   "Write a short story about a robot learning to love:\n\n"
 * );
 */
export class CohereTextGenerationModel extends AbstractModel {
    constructor(settings) {
        super({ settings });
        Object.defineProperty(this, "provider", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "cohere"
        });
        Object.defineProperty(this, "contextWindowSize", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "tokenizer", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.contextWindowSize =
            COHERE_TEXT_GENERATION_MODELS[this.settings.model].contextWindowSize;
        this.tokenizer = new CohereTokenizer({
            api: this.settings.api,
            model: this.settings.model,
        });
    }
    get modelName() {
        return this.settings.model;
    }
    async countPromptTokens(input) {
        return countTokens(this.tokenizer, input);
    }
    async callAPI(prompt, options) {
        return callWithRetryAndThrottle({
            retry: this.settings.api?.retry,
            throttle: this.settings.api?.throttle,
            call: async () => callCohereTextGenerationAPI({
                ...this.settings,
                // use endSequences instead of stopSequences
                // to exclude stop tokens from the generated text
                endSequences: this.settings.stopSequences,
                maxTokens: this.settings.maxCompletionTokens,
                // mapped name because of conflict with stopSequences:
                stopSequences: this.settings.cohereStopSequences,
                abortSignal: options.run?.abortSignal,
                responseFormat: options.responseFormat,
                prompt,
            }),
        });
    }
    get settingsForEvent() {
        const eventSettingProperties = [
            "maxCompletionTokens",
            "stopSequences",
            "numGenerations",
            "temperature",
            "k",
            "p",
            "frequencyPenalty",
            "presencePenalty",
            "returnLikelihoods",
            "logitBias",
            "truncate",
            "cohereStopSequences",
        ];
        return Object.fromEntries(Object.entries(this.settings).filter(([key]) => eventSettingProperties.includes(key)));
    }
    async doGenerateText(prompt, options) {
        const response = await this.callAPI(prompt, {
            ...options,
            responseFormat: CohereTextGenerationResponseFormat.json,
        });
        return {
            response,
            text: response.generations[0].text,
        };
    }
    doStreamText(prompt, options) {
        return this.callAPI(prompt, {
            ...options,
            responseFormat: CohereTextGenerationResponseFormat.deltaIterable,
        });
    }
    extractTextDelta(fullDelta) {
        return fullDelta.delta;
    }
    /**
     * Returns this model with an instruction prompt format.
     */
    withInstructionPrompt() {
        return this.withPromptFormat(mapInstructionPromptToTextFormat());
    }
    /**
     * Returns this model with a chat prompt format.
     */
    withChatPrompt(options) {
        return this.withPromptFormat(mapChatPromptToTextFormat(options));
    }
    withPromptFormat(promptFormat) {
        return new PromptFormatTextStreamingModel({
            model: this.withSettings({
                stopSequences: [
                    ...(this.settings.stopSequences ?? []),
                    ...promptFormat.stopSequences,
                ],
            }),
            promptFormat,
        });
    }
    withSettings(additionalSettings) {
        return new CohereTextGenerationModel(Object.assign({}, this.settings, additionalSettings));
    }
}
const cohereTextGenerationResponseSchema = z.object({
    id: z.string(),
    generations: z.array(z.object({
        id: z.string(),
        text: z.string(),
        finish_reason: z.string().optional(),
    })),
    prompt: z.string(),
    meta: z
        .object({
        api_version: z.object({
            version: z.string(),
        }),
    })
        .optional(),
});
async function callCohereTextGenerationAPI({ api = new CohereApiConfiguration(), abortSignal, responseFormat, model, prompt, numGenerations, maxTokens, temperature, k, p, frequencyPenalty, presencePenalty, endSequences, stopSequences, returnLikelihoods, logitBias, truncate, }) {
    return postJsonToApi({
        url: api.assembleUrl(`/generate`),
        headers: api.headers,
        body: {
            stream: responseFormat.stream,
            model,
            prompt,
            num_generations: numGenerations,
            max_tokens: maxTokens,
            temperature,
            k,
            p,
            frequency_penalty: frequencyPenalty,
            presence_penalty: presencePenalty,
            end_sequences: endSequences,
            stop_sequences: stopSequences,
            return_likelihoods: returnLikelihoods,
            logit_bias: logitBias,
            truncate,
        },
        failedResponseHandler: failedCohereCallResponseHandler,
        successfulResponseHandler: responseFormat.handler,
        abortSignal,
    });
}
const cohereTextStreamingResponseSchema = z.discriminatedUnion("is_finished", [
    z.object({
        text: z.string(),
        is_finished: z.literal(false),
    }),
    z.object({
        is_finished: z.literal(true),
        finish_reason: z.string(),
        response: cohereTextGenerationResponseSchema,
    }),
]);
async function createCohereTextGenerationFullDeltaIterableQueue(stream) {
    const queue = new AsyncQueue();
    let accumulatedText = "";
    function processLine(line) {
        const event = parseJsonWithZod(line, cohereTextStreamingResponseSchema);
        if (event.is_finished === true) {
            queue.push({
                type: "delta",
                fullDelta: {
                    content: accumulatedText,
                    isComplete: true,
                    delta: "",
                },
                valueDelta: "",
            });
        }
        else {
            accumulatedText += event.text;
            queue.push({
                type: "delta",
                fullDelta: {
                    content: accumulatedText,
                    isComplete: false,
                    delta: event.text,
                },
                valueDelta: event.text,
            });
        }
    }
    // process the stream asynchonously (no 'await' on purpose):
    (async () => {
        try {
            let unprocessedText = "";
            const reader = new ReadableStreamDefaultReader(stream);
            const utf8Decoder = new TextDecoder("utf-8");
            // eslint-disable-next-line no-constant-condition
            while (true) {
                const { value: chunk, done } = await reader.read();
                if (done) {
                    break;
                }
                unprocessedText += utf8Decoder.decode(chunk, { stream: true });
                const processableLines = unprocessedText.split(/\r\n|\n|\r/g);
                unprocessedText = processableLines.pop() || "";
                processableLines.forEach(processLine);
            }
            // processing remaining text:
            if (unprocessedText) {
                processLine(unprocessedText);
            }
        }
        finally {
            queue.close();
        }
    })();
    return queue;
}
export const CohereTextGenerationResponseFormat = {
    /**
     * Returns the response as a JSON object.
     */
    json: {
        stream: false,
        handler: createJsonResponseHandler(cohereTextGenerationResponseSchema),
    },
    /**
     * Returns an async iterable over the full deltas (all choices, including full current state at time of event)
     * of the response stream.
     */
    deltaIterable: {
        stream: true,
        handler: async ({ response }) => createCohereTextGenerationFullDeltaIterableQueue(response.body),
    },
};
