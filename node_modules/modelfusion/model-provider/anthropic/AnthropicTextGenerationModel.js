import { z } from "zod";
import { callWithRetryAndThrottle } from "../../core/api/callWithRetryAndThrottle.js";
import { createJsonResponseHandler, postJsonToApi, } from "../../core/api/postToApi.js";
import { AsyncQueue } from "../../event-source/AsyncQueue.js";
import { parseEventSourceStream } from "../../event-source/parseEventSourceStream.js";
import { AbstractModel } from "../../model-function/AbstractModel.js";
import { PromptFormatTextStreamingModel } from "../../model-function/generate-text/PromptFormatTextStreamingModel.js";
import { parseJsonWithZod } from "../../util/parseJSON.js";
import { AnthropicApiConfiguration } from "./AnthropicApiConfiguration.js";
import { failedAnthropicCallResponseHandler } from "./AnthropicError.js";
import { mapChatPromptToAnthropicFormat, mapInstructionPromptToAnthropicFormat, } from "./AnthropicPromptFormat.js";
export const ANTHROPIC_TEXT_GENERATION_MODELS = {
    "claude-instant-1": {
        contextWindowSize: 100000,
    },
    "claude-instant-1.2": {
        contextWindowSize: 100000,
    },
    "claude-2": {
        contextWindowSize: 100000,
    },
    "claude-2.0": {
        contextWindowSize: 100000,
    },
};
/**
 * Create a text generation model that calls the Anthropic API.
 *
 * @see https://docs.anthropic.com/claude/reference/complete_post
 */
export class AnthropicTextGenerationModel extends AbstractModel {
    constructor(settings) {
        super({ settings });
        Object.defineProperty(this, "provider", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "anthropic"
        });
        Object.defineProperty(this, "contextWindowSize", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "tokenizer", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: undefined
        });
        Object.defineProperty(this, "countPromptTokens", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: undefined
        });
        this.contextWindowSize =
            ANTHROPIC_TEXT_GENERATION_MODELS[this.settings.model].contextWindowSize;
    }
    get modelName() {
        return this.settings.model;
    }
    async callAPI(prompt, options) {
        return callWithRetryAndThrottle({
            retry: this.settings.api?.retry,
            throttle: this.settings.api?.throttle,
            call: async () => callAnthropicTextGenerationAPI({
                ...this.settings,
                stopSequences: this.settings.stopSequences,
                maxTokens: this.settings.maxCompletionTokens,
                abortSignal: options.run?.abortSignal,
                responseFormat: options.responseFormat,
                prompt,
            }),
        });
    }
    get settingsForEvent() {
        const eventSettingProperties = [
            "maxCompletionTokens",
            "stopSequences",
            "temperature",
            "topK",
            "topP",
            "userId",
        ];
        return Object.fromEntries(Object.entries(this.settings).filter(([key]) => eventSettingProperties.includes(key)));
    }
    async doGenerateText(prompt, options) {
        const response = await this.callAPI(prompt, {
            ...options,
            responseFormat: AnthropicTextGenerationResponseFormat.json,
        });
        return {
            response,
            text: response.completion,
        };
    }
    doStreamText(prompt, options) {
        return this.callAPI(prompt, {
            ...options,
            responseFormat: AnthropicTextGenerationResponseFormat.deltaIterable,
        });
    }
    /**
     * Returns this model with an instruction prompt format.
     */
    withInstructionPrompt() {
        return this.withPromptFormat(mapInstructionPromptToAnthropicFormat());
    }
    /**
     * Returns this model with a chat prompt format.
     */
    withChatPrompt() {
        return this.withPromptFormat(mapChatPromptToAnthropicFormat());
    }
    withPromptFormat(promptFormat) {
        return new PromptFormatTextStreamingModel({
            model: this.withSettings({
                stopSequences: [
                    ...(this.settings.stopSequences ?? []),
                    ...promptFormat.stopSequences,
                ],
            }),
            promptFormat,
        });
    }
    withSettings(additionalSettings) {
        return new AnthropicTextGenerationModel(Object.assign({}, this.settings, additionalSettings));
    }
}
const anthropicTextGenerationResponseSchema = z.object({
    completion: z.string(),
    stop_reason: z.string(),
    model: z.string(),
});
async function callAnthropicTextGenerationAPI({ api = new AnthropicApiConfiguration(), abortSignal, responseFormat, model, prompt, maxTokens, stopSequences, temperature, topK, topP, userId, }) {
    return postJsonToApi({
        url: api.assembleUrl(`/complete`),
        headers: api.headers,
        body: {
            model,
            prompt,
            stream: responseFormat.stream,
            max_tokens_to_sample: maxTokens,
            temperature,
            top_k: topK,
            top_p: topP,
            stop_sequences: stopSequences,
            metadata: userId != null ? { user_id: userId } : undefined,
        },
        failedResponseHandler: failedAnthropicCallResponseHandler,
        successfulResponseHandler: responseFormat.handler,
        abortSignal,
    });
}
const anthropicTextStreamingResponseSchema = z.object({
    completion: z.string(),
    stop_reason: z.string().nullable(),
    model: z.string(),
});
async function createAnthropicFullDeltaIterableQueue(stream) {
    const queue = new AsyncQueue();
    let content = "";
    // process the stream asynchonously (no 'await' on purpose):
    parseEventSourceStream({ stream })
        .then(async (events) => {
        try {
            for await (const event of events) {
                if (event.event === "error") {
                    queue.push({ type: "error", error: event.data });
                    queue.close();
                    return;
                }
                if (event.event !== "completion") {
                    continue;
                }
                const data = event.data;
                const eventData = parseJsonWithZod(data, anthropicTextStreamingResponseSchema);
                content += eventData.completion;
                queue.push({
                    type: "delta",
                    fullDelta: {
                        content,
                        isComplete: eventData.stop_reason != null,
                        delta: eventData.completion,
                    },
                    valueDelta: eventData.completion,
                });
                if (eventData.stop_reason != null) {
                    queue.close();
                }
            }
        }
        catch (error) {
            queue.push({ type: "error", error });
            queue.close();
        }
    })
        .catch((error) => {
        queue.push({ type: "error", error });
        queue.close();
    });
    return queue;
}
export const AnthropicTextGenerationResponseFormat = {
    /**
     * Returns the response as a JSON object.
     */
    json: {
        stream: false,
        handler: createJsonResponseHandler(anthropicTextGenerationResponseSchema),
    },
    /**
     * Returns an async iterable over the full deltas (all choices, including full current state at time of event)
     * of the response stream.
     */
    deltaIterable: {
        stream: true,
        handler: async ({ response }) => createAnthropicFullDeltaIterableQueue(response.body),
    },
};
